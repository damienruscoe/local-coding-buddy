# Future Work and Architectural Improvements

This document tracks potential future work, architectural changes, and other improvements for the local-coding-buddy project that have been identified during development.

## Agent and Workflow Enhancements

### 1. Improve Context for Implementer Agent
- **Issue**: The `implementer` agent currently operates without knowledge of the filesystem. It doesn't know if a file it needs to modify already exists.
- **Proposed Solution**: The orchestrator (`StateMachine`) should provide file-system context to the `implementer`. Before calling the agent, it could check for the existence of target files and include this information (and even file content) in the prompt. This would allow the agent to make a more intelligent decision about whether to create a new file or modify an existing one.

### 2. Guard Against Agent "Hallucinations"
- **Issue**: LLM-based agents can sometimes "hallucinate" or invent features, libraries, or decorators that don't exist (e.g., the `spec_author` inventing an `@unittest.dataProvider` decorator).
- **Proposed Solution**: Investigate methods for better grounding the agents. This could involve:
    - Providing relevant snippets of library documentation in the prompt.
    - Using more explicit and restrictive prompts that guide the agent to use specific, standard libraries and patterns.
    - Implementing a validation step that specifically checks for the use of non-standard or invented features in the generated code.

### 3. Add a Plan Review Stage
- **Issue**: The quality of the entire workflow is highly dependent on the initial plan generated by the `architect`. A flawed plan can cause the entire process to fail.
- **Proposed Solution**: Introduce a "plan review" step. This could be another agent (`plan_reviewer`) or a feedback loop where the `architect`'s plan is validated for logical consistency, correct dependency mapping, and feature-centric task decomposition before being passed to the downstream agents.

## Testing and Validation Framework

### 1. Implement C++ Code Coverage
- **Issue**: The current validation framework does not have a mechanism to measure code coverage for C++ projects.
- **Proposed Solution**:
    - Modify the `_run_ctest` method in `validators.py`.
    - The CMake configuration step should be modified to include the `--coverage` flag (for GCC/Clang) when building in Debug mode (e.g., `-DCMAKE_BUILD_TYPE=Debug -DCMAKE_CXX_FLAGS="--coverage"`).
    - After `ctest` runs, execute `gcov` or `lcov` to process the generated `.gcda` files and produce a coverage report.
    - The coverage percentage should be parsed from this report and returned.

### 2. Create an Extensible, Multi-Language Coverage Strategy
- **Issue**: The coverage logic in `validators.py` is specific to Python. Adding C++ and other languages will require a more scalable approach.
- **Proposed Solution**: Refactor the coverage-checking logic into a strategy pattern. A `CoverageStrategy` interface could be defined, with concrete implementations for different languages (e.g., `PythonCoverageStrategy`, `CppCoverageStrategy`). The validator would select the appropriate strategy based on the project's language.

## General Extensibility

### 1. Make Agent Prompts More Extensible
- **Issue**: Some prompts contain hard-coded examples for specific languages or tools (e.g., suggesting `pytest` for Python).
- **Proposed Solution**: While prompts have been improved, a future iteration could involve a more dynamic prompt generation system. The orchestrator could have a registry of language-specific toolchains and idiomatic patterns, and use this to inject highly relevant examples and instructions into the prompts at runtime, rather than having them in static strings.
